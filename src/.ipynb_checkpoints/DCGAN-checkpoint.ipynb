{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wbs9g54JEkzE"
   },
   "outputs": [],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CUDA = True\n",
    "DATA_PATH = '../../Data/fashionmnist'\n",
    "OUT_PATH = 'output'\n",
    "LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNEL = 1\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 3\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 1\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 4th layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # output layer\n",
    "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVe4iz9ZEtym"
   },
   "outputs": [],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    \"\"\"Create a folder if it does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "    except OSError as _e:\n",
    "        if _e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def to_np(var):\n",
    "    \"\"\"Exports torch.Tensor to Numpy array.\n",
    "    \"\"\"\n",
    "    return var.detach().cpu().numpy()\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    \"\"\"Clear all contents recursively if the folder exists.\n",
    "    Create the folder if it has been accidently deleted.\n",
    "    \"\"\"\n",
    "    create_folder(folder_path)\n",
    "    for the_file in os.listdir(folder_path):\n",
    "        _file_path = os.path.join(folder_path, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(_file_path):\n",
    "                os.unlink(_file_path)\n",
    "            elif os.path.isdir(_file_path):\n",
    "                shutil.rmtree(_file_path)\n",
    "        except OSError as _e:\n",
    "            print(_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fTklKxw-FN-N",
    "outputId": "b4521ee0-e547-40bd-de06-72bc9b62b46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.4.0\n",
      "CUDA version: 10.1\n",
      "\n",
      "Random Seed:  1\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "generator params 3574656\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n",
      "discrimator params 2763520\n",
      "Epoch 0 [0/469] loss_D_real: 1.0402 loss_D_fake: 1.0658 loss_G: 2.9690\n",
      "Epoch 0 [100/469] loss_D_real: 0.2726 loss_D_fake: 0.0723 loss_G: 4.3301\n",
      "Epoch 0 [200/469] loss_D_real: 0.0133 loss_D_fake: 0.4809 loss_G: 4.3459\n",
      "Epoch 0 [300/469] loss_D_real: 0.1549 loss_D_fake: 0.1987 loss_G: 3.4037\n",
      "Epoch 0 [400/469] loss_D_real: 0.0894 loss_D_fake: 0.1624 loss_G: 3.3865\n",
      "Epoch 1 [0/469] loss_D_real: 0.2217 loss_D_fake: 0.2209 loss_G: 2.6713\n",
      "Epoch 1 [100/469] loss_D_real: 0.1719 loss_D_fake: 0.4091 loss_G: 3.2421\n",
      "Epoch 1 [200/469] loss_D_real: 0.2819 loss_D_fake: 0.1242 loss_G: 2.1415\n",
      "Epoch 1 [300/469] loss_D_real: 0.0811 loss_D_fake: 0.2083 loss_G: 3.3321\n",
      "Epoch 1 [400/469] loss_D_real: 0.1240 loss_D_fake: 0.3751 loss_G: 3.7759\n",
      "Epoch 2 [0/469] loss_D_real: 0.2608 loss_D_fake: 0.5342 loss_G: 2.9425\n",
      "Epoch 2 [100/469] loss_D_real: 0.2198 loss_D_fake: 0.0994 loss_G: 3.0181\n",
      "Epoch 2 [200/469] loss_D_real: 0.1862 loss_D_fake: 0.2824 loss_G: 2.6239\n",
      "Epoch 2 [300/469] loss_D_real: 0.1504 loss_D_fake: 0.4173 loss_G: 3.3715\n",
      "Epoch 2 [400/469] loss_D_real: 0.2423 loss_D_fake: 0.0592 loss_G: 2.6576\n",
      "Epoch 3 [0/469] loss_D_real: 0.2208 loss_D_fake: 0.0740 loss_G: 2.8865\n",
      "Epoch 3 [100/469] loss_D_real: 0.0685 loss_D_fake: 0.1553 loss_G: 3.7601\n",
      "Epoch 3 [200/469] loss_D_real: 0.1240 loss_D_fake: 0.2064 loss_G: 2.8353\n",
      "Epoch 3 [300/469] loss_D_real: 0.0589 loss_D_fake: 0.2630 loss_G: 4.1616\n",
      "Epoch 3 [400/469] loss_D_real: 0.0998 loss_D_fake: 0.3754 loss_G: 4.2229\n",
      "Epoch 4 [0/469] loss_D_real: 0.0405 loss_D_fake: 0.3167 loss_G: 4.5407\n",
      "Epoch 4 [100/469] loss_D_real: 0.1661 loss_D_fake: 0.2343 loss_G: 3.5581\n",
      "Epoch 4 [200/469] loss_D_real: 0.0304 loss_D_fake: 0.3413 loss_G: 3.9429\n",
      "Epoch 4 [300/469] loss_D_real: 0.2120 loss_D_fake: 0.2822 loss_G: 2.8276\n",
      "Epoch 4 [400/469] loss_D_real: 0.2079 loss_D_fake: 0.1105 loss_G: 2.7995\n",
      "Epoch 5 [0/469] loss_D_real: 0.0023 loss_D_fake: 2.9859 loss_G: 9.0983\n",
      "Epoch 5 [100/469] loss_D_real: 0.1474 loss_D_fake: 0.0415 loss_G: 3.2262\n",
      "Epoch 5 [200/469] loss_D_real: 0.0384 loss_D_fake: 0.1365 loss_G: 3.5935\n",
      "Epoch 5 [300/469] loss_D_real: 0.1334 loss_D_fake: 0.0345 loss_G: 3.2247\n",
      "Epoch 5 [400/469] loss_D_real: 0.0941 loss_D_fake: 0.0474 loss_G: 3.4558\n",
      "Epoch 6 [0/469] loss_D_real: 0.2664 loss_D_fake: 0.2588 loss_G: 3.0768\n",
      "Epoch 6 [100/469] loss_D_real: 0.0980 loss_D_fake: 0.3106 loss_G: 3.8985\n",
      "Epoch 6 [200/469] loss_D_real: 0.0745 loss_D_fake: 0.0770 loss_G: 3.1198\n",
      "Epoch 6 [300/469] loss_D_real: 0.4730 loss_D_fake: 0.9691 loss_G: 1.9801\n",
      "Epoch 6 [400/469] loss_D_real: 0.0859 loss_D_fake: 0.1936 loss_G: 3.4247\n",
      "Epoch 7 [0/469] loss_D_real: 0.0695 loss_D_fake: 0.1237 loss_G: 3.2801\n",
      "Epoch 7 [100/469] loss_D_real: 0.2215 loss_D_fake: 0.1530 loss_G: 3.0699\n",
      "Epoch 7 [200/469] loss_D_real: 0.4439 loss_D_fake: 0.1028 loss_G: 2.3723\n",
      "Epoch 7 [300/469] loss_D_real: 0.0866 loss_D_fake: 0.0398 loss_G: 3.1080\n",
      "Epoch 7 [400/469] loss_D_real: 0.0627 loss_D_fake: 0.0453 loss_G: 3.5311\n",
      "Epoch 8 [0/469] loss_D_real: 0.6324 loss_D_fake: 0.2606 loss_G: 1.6435\n",
      "Epoch 8 [100/469] loss_D_real: 0.6797 loss_D_fake: 0.0400 loss_G: 1.7018\n",
      "Epoch 8 [200/469] loss_D_real: 0.0904 loss_D_fake: 0.1122 loss_G: 3.4993\n",
      "Epoch 8 [300/469] loss_D_real: 6.5601 loss_D_fake: 0.0001 loss_G: 1.6390\n",
      "Epoch 8 [400/469] loss_D_real: 0.0221 loss_D_fake: 0.1347 loss_G: 4.3991\n",
      "Epoch 9 [0/469] loss_D_real: 0.0408 loss_D_fake: 0.1571 loss_G: 4.0991\n",
      "Epoch 9 [100/469] loss_D_real: 0.0165 loss_D_fake: 0.0617 loss_G: 4.5564\n",
      "Epoch 9 [200/469] loss_D_real: 0.2466 loss_D_fake: 0.6983 loss_G: 2.3323\n",
      "Epoch 9 [300/469] loss_D_real: 0.2166 loss_D_fake: 0.1781 loss_G: 2.9906\n",
      "Epoch 9 [400/469] loss_D_real: 0.0735 loss_D_fake: 0.0140 loss_G: 4.1392\n",
      "Epoch 10 [0/469] loss_D_real: 0.1328 loss_D_fake: 1.3188 loss_G: 3.1224\n",
      "Epoch 10 [100/469] loss_D_real: 0.0161 loss_D_fake: 0.0985 loss_G: 4.7625\n",
      "Epoch 10 [200/469] loss_D_real: 0.0221 loss_D_fake: 0.0778 loss_G: 4.4979\n",
      "Epoch 10 [300/469] loss_D_real: 0.1165 loss_D_fake: 0.1392 loss_G: 3.5099\n",
      "Epoch 10 [400/469] loss_D_real: 0.0614 loss_D_fake: 0.0303 loss_G: 3.5331\n",
      "Epoch 11 [0/469] loss_D_real: 0.1126 loss_D_fake: 0.0276 loss_G: 3.9146\n",
      "Epoch 11 [100/469] loss_D_real: 0.5477 loss_D_fake: 0.1773 loss_G: 2.3416\n",
      "Epoch 11 [200/469] loss_D_real: 0.0125 loss_D_fake: 0.0511 loss_G: 4.2689\n",
      "Epoch 11 [300/469] loss_D_real: 0.0091 loss_D_fake: 0.9702 loss_G: 7.1798\n",
      "Epoch 11 [400/469] loss_D_real: 0.0417 loss_D_fake: 0.0379 loss_G: 3.6957\n",
      "Epoch 12 [0/469] loss_D_real: 0.0974 loss_D_fake: 0.0953 loss_G: 3.0508\n",
      "Epoch 12 [100/469] loss_D_real: 0.0640 loss_D_fake: 0.0138 loss_G: 3.3664\n",
      "Epoch 12 [200/469] loss_D_real: 2.5387 loss_D_fake: 0.0044 loss_G: 0.3655\n",
      "Epoch 12 [300/469] loss_D_real: 0.0193 loss_D_fake: 0.0461 loss_G: 4.1965\n",
      "Epoch 12 [400/469] loss_D_real: 0.0226 loss_D_fake: 0.0372 loss_G: 4.3291\n",
      "Epoch 13 [0/469] loss_D_real: 0.4086 loss_D_fake: 0.3203 loss_G: 2.3869\n",
      "Epoch 13 [100/469] loss_D_real: 0.1195 loss_D_fake: 0.3883 loss_G: 3.6234\n",
      "Epoch 13 [200/469] loss_D_real: 0.0108 loss_D_fake: 0.5278 loss_G: 6.8590\n",
      "Epoch 13 [300/469] loss_D_real: 0.0213 loss_D_fake: 0.0184 loss_G: 4.3488\n",
      "Epoch 13 [400/469] loss_D_real: 0.0499 loss_D_fake: 3.6040 loss_G: 3.0422\n",
      "Epoch 14 [0/469] loss_D_real: 0.0378 loss_D_fake: 0.0113 loss_G: 4.2589\n",
      "Epoch 14 [100/469] loss_D_real: 0.0734 loss_D_fake: 0.0060 loss_G: 3.9519\n",
      "Epoch 14 [200/469] loss_D_real: 0.0788 loss_D_fake: 0.0043 loss_G: 3.0332\n",
      "Epoch 14 [300/469] loss_D_real: 0.2466 loss_D_fake: 0.1182 loss_G: 2.9997\n",
      "Epoch 14 [400/469] loss_D_real: 0.1153 loss_D_fake: 0.0863 loss_G: 3.6563\n",
      "Epoch 15 [0/469] loss_D_real: 0.5672 loss_D_fake: 0.1010 loss_G: 2.1603\n",
      "Epoch 15 [100/469] loss_D_real: 0.4207 loss_D_fake: 0.1318 loss_G: 2.2294\n",
      "Epoch 15 [200/469] loss_D_real: 0.1880 loss_D_fake: 0.3396 loss_G: 3.0130\n",
      "Epoch 15 [300/469] loss_D_real: 0.3492 loss_D_fake: 0.4921 loss_G: 1.7322\n",
      "Epoch 15 [400/469] loss_D_real: 0.1000 loss_D_fake: 0.1375 loss_G: 4.0379\n",
      "Epoch 16 [0/469] loss_D_real: 0.0162 loss_D_fake: 0.0530 loss_G: 4.1521\n",
      "Epoch 16 [100/469] loss_D_real: 0.0701 loss_D_fake: 0.0155 loss_G: 4.5755\n",
      "Epoch 16 [200/469] loss_D_real: 0.0481 loss_D_fake: 0.6708 loss_G: 5.7972\n",
      "Epoch 16 [300/469] loss_D_real: 0.3166 loss_D_fake: 0.2332 loss_G: 2.6197\n",
      "Epoch 16 [400/469] loss_D_real: 0.0394 loss_D_fake: 0.0643 loss_G: 4.6715\n",
      "Epoch 17 [0/469] loss_D_real: 0.0117 loss_D_fake: 0.0470 loss_G: 4.9621\n",
      "Epoch 17 [100/469] loss_D_real: 0.3942 loss_D_fake: 0.0798 loss_G: 3.1081\n",
      "Epoch 17 [200/469] loss_D_real: 0.0898 loss_D_fake: 0.0858 loss_G: 4.4871\n",
      "Epoch 17 [300/469] loss_D_real: 0.0137 loss_D_fake: 0.0115 loss_G: 4.8207\n",
      "Epoch 17 [400/469] loss_D_real: 0.0185 loss_D_fake: 0.0121 loss_G: 4.8045\n",
      "Epoch 18 [0/469] loss_D_real: 0.0108 loss_D_fake: 0.0136 loss_G: 4.8884\n",
      "Epoch 18 [100/469] loss_D_real: 9.4038 loss_D_fake: 0.0001 loss_G: 0.9006\n",
      "Epoch 18 [200/469] loss_D_real: 0.0314 loss_D_fake: 0.0343 loss_G: 4.2180\n",
      "Epoch 18 [300/469] loss_D_real: 1.5444 loss_D_fake: 0.0112 loss_G: 2.0189\n",
      "Epoch 18 [400/469] loss_D_real: 0.0642 loss_D_fake: 0.2888 loss_G: 4.1343\n",
      "Epoch 19 [0/469] loss_D_real: 0.0241 loss_D_fake: 0.1575 loss_G: 4.7879\n",
      "Epoch 19 [100/469] loss_D_real: 0.4412 loss_D_fake: 0.4364 loss_G: 1.7263\n",
      "Epoch 19 [200/469] loss_D_real: 0.1802 loss_D_fake: 0.2757 loss_G: 2.9979\n",
      "Epoch 19 [300/469] loss_D_real: 0.0472 loss_D_fake: 0.0174 loss_G: 3.8208\n",
      "Epoch 19 [400/469] loss_D_real: 0.0353 loss_D_fake: 0.0879 loss_G: 3.9030\n",
      "Epoch 20 [0/469] loss_D_real: 0.0274 loss_D_fake: 0.0042 loss_G: 5.7542\n",
      "Epoch 20 [100/469] loss_D_real: 0.0492 loss_D_fake: 0.1574 loss_G: 5.2943\n",
      "Epoch 20 [200/469] loss_D_real: 0.1562 loss_D_fake: 0.8216 loss_G: 4.6123\n",
      "Epoch 20 [300/469] loss_D_real: 0.1154 loss_D_fake: 0.0315 loss_G: 3.2148\n",
      "Epoch 20 [400/469] loss_D_real: 0.0325 loss_D_fake: 0.0131 loss_G: 4.4511\n",
      "Epoch 21 [0/469] loss_D_real: 0.0158 loss_D_fake: 1.1769 loss_G: 6.7616\n",
      "Epoch 21 [100/469] loss_D_real: 0.0115 loss_D_fake: 0.0835 loss_G: 5.6017\n",
      "Epoch 21 [200/469] loss_D_real: 1.4153 loss_D_fake: 0.0947 loss_G: 0.9537\n",
      "Epoch 21 [300/469] loss_D_real: 0.0138 loss_D_fake: 1.3324 loss_G: 7.2044\n",
      "Epoch 21 [400/469] loss_D_real: 0.0005 loss_D_fake: 1.5585 loss_G: 9.6131\n",
      "Epoch 22 [0/469] loss_D_real: 0.0567 loss_D_fake: 0.0371 loss_G: 3.5336\n",
      "Epoch 22 [100/469] loss_D_real: 0.0606 loss_D_fake: 0.0593 loss_G: 4.4147\n",
      "Epoch 22 [200/469] loss_D_real: 0.0066 loss_D_fake: 0.0282 loss_G: 4.6845\n",
      "Epoch 22 [300/469] loss_D_real: 0.1534 loss_D_fake: 0.1105 loss_G: 3.0063\n",
      "Epoch 22 [400/469] loss_D_real: 0.1442 loss_D_fake: 0.5360 loss_G: 3.7170\n",
      "Epoch 23 [0/469] loss_D_real: 0.0146 loss_D_fake: 0.0252 loss_G: 4.7090\n",
      "Epoch 23 [100/469] loss_D_real: 0.0233 loss_D_fake: 0.0094 loss_G: 4.4403\n",
      "Epoch 23 [200/469] loss_D_real: 0.0235 loss_D_fake: 1.0785 loss_G: 10.5575\n",
      "Epoch 23 [300/469] loss_D_real: 0.0498 loss_D_fake: 0.0188 loss_G: 4.0848\n",
      "Epoch 23 [400/469] loss_D_real: 0.0143 loss_D_fake: 0.0211 loss_G: 5.2557\n",
      "Epoch 24 [0/469] loss_D_real: 0.0079 loss_D_fake: 0.0078 loss_G: 5.5565\n",
      "Epoch 24 [100/469] loss_D_real: 0.4673 loss_D_fake: 0.2558 loss_G: 1.6145\n",
      "Epoch 24 [200/469] loss_D_real: 0.8705 loss_D_fake: 0.0100 loss_G: 1.2274\n",
      "Epoch 24 [300/469] loss_D_real: 0.0338 loss_D_fake: 0.0422 loss_G: 4.3938\n",
      "Epoch 24 [400/469] loss_D_real: 0.0915 loss_D_fake: 0.2916 loss_G: 4.5102\n"
     ]
    }
   ],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "#import statsmodels.api as sm    # to estimate an average with 'loess'\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import rc\n",
    "#rc('font', **font)\n",
    "#rc('text', usetex=True)\n",
    "import pandas as pd\n",
    "import random, string\n",
    "import os, time, datetime, json\n",
    "# perso libraries\n",
    "# from utils.toolbox import *\n",
    "# from utils.dcgan import *\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "#rc('font', **font)\n",
    "#rc('text', usetex=True)\n",
    "import pandas as pd\n",
    "import random, string\n",
    "import os, time, datetime, json\n",
    "#-------------------------------------------------#\n",
    "#               A) Hyper-parameters               #\n",
    "#-------------------------------------------------#\n",
    "CUDA = True\n",
    "DATA_PATH = '../dataset/fashionmnist'\n",
    "OUT_PATH = '../output'\n",
    "#LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNEL = 1\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 25\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 1\n",
    "#-------------------------------------------------#\n",
    "#               B) Data/Model/Loss                #\n",
    "#-------------------------------------------------#\n",
    "# B.1) dataset/corpus\n",
    "#--------------------\n",
    "# Corpus\n",
    "# print the number of parameters\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "clear_folder(OUT_PATH)\n",
    "#print(\"Logging to {}\\n\".format(LOG_FILE))\n",
    "#sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "nbr_param = sum(p.numel() for p in netG.parameters() if p.requires_grad)\n",
    "print(\"generator params\", nbr_param)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "nbr_param = sum(p.numel() for p in netD.parameters() if p.requires_grad)\n",
    "print(\"discrimator params\", nbr_param)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "dataset = dset.FashionMNIST(root=DATA_PATH, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                     transforms.Resize(X_DIM),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "counter=0\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x_real = data[0].to(device)\n",
    "        # if counter == 0:\n",
    "        #     print(\"data0.shape()\", data[0].shape)\n",
    "        #     print(\"data1.shape()\", data[1].shape)\n",
    "        #     print(\"data\",data)\n",
    "        #     print(\"x_real.size\",x_real.shape)\n",
    "        #     counter+=1\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL, device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, device=device)\n",
    "\n",
    "        # Update D with real data\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = criterion(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # Update D with fake data\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = criterion(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update G with fake data\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = criterion(y_fake_r, real_label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(epoch, i, len(dataloader),loss_D_real.mean().item(),loss_D_fake.mean().item(),loss_G.mean().item()))\n",
    "            vutils.save_image(x_real, os.path.join(OUT_PATH, 'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                vutils.save_image(viz_sample, os.path.join(OUT_PATH, 'fake_samples_{}.png'.format(epoch)), normalize=True)\n",
    "    torch.save(netG.state_dict(), os.path.join(OUT_PATH, 'netG_{}.pth'.format(epoch)))\n",
    "    torch.save(netD.state_dict(), os.path.join(OUT_PATH, 'netD_{}.pth'.format(epoch)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "82KGeGwqFYzS",
    "outputId": "76202ec8-2d9e-4271-dedb-3b59d52f74a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.4.0\n",
      "CUDA version: 10.1\n",
      "\n",
      "Random Seed:  2583\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "#import utils\n",
    "\n",
    "CUDA = True     # Change to False for CPU training\n",
    "VIZ_MODE = 1    # 0: random; 1: interpolation; 2: semantic calculation\n",
    "OUT_PATH = '../output'\n",
    "IMAGE_PATH = '../classes'\n",
    "#LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 1        # Adjust this value according to your GPU memory\n",
    "IMAGE_CHANNEL = 1\n",
    "# IMAGE_CHANNEL = 3\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "seed = None            # Change to None to get different results at each run\n",
    "\n",
    "#print(\"Logging to {}\\n\".format(LOG_FILE))\n",
    "#sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = False      # May train faster but cost more memory\n",
    "\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "netG = Generator()\n",
    "netG.load_state_dict(torch.load(os.path.join(OUT_PATH, 'netG_29.pth'),map_location=torch.device('cpu')))\n",
    "netG.to(device)\n",
    "\n",
    "for i in range(50):\n",
    "    if VIZ_MODE == 0:\n",
    "        viz_tensor = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "    elif VIZ_MODE == 1:\n",
    "        load_vector = np.loadtxt(os.path.join(OUT_PATH, 'vec_20200424-081820.txt'))\n",
    "        xp = [0, 1]\n",
    "        yp = np.vstack([load_vector[2], load_vector[9]])   # choose two exemplar vectors\n",
    "        xvals = np.linspace(0, 1, num=BATCH_SIZE)\n",
    "        sample = interp1d(xp, yp, axis=0)\n",
    "        viz_tensor = torch.tensor(sample(xvals).reshape(BATCH_SIZE, Z_DIM, 1, 1), dtype=torch.float32, device=device)\n",
    "    elif VIZ_MODE == 2:\n",
    "        load_vector = np.loadtxt(os.path.join(OUT_PATH, 'vec_20200424-081820.txt'))\n",
    "        z1 = (load_vector[0] + load_vector[6] + load_vector[8]) / 3.\n",
    "        z2 = (load_vector[1] + load_vector[2] + load_vector[4]) / 3.\n",
    "        z3 = (load_vector[3] + load_vector[4] + load_vector[6]) / 3.\n",
    "        z_new = z1 - z2 + z3\n",
    "        sample = np.zeros(shape=(BATCH_SIZE, Z_DIM))\n",
    "        for i in range(BATCH_SIZE):\n",
    "            sample[i] = z_new + 0.1 * np.random.normal(-1.0, 1.0, 100)\n",
    "        viz_tensor = torch.tensor(sample.reshape(BATCH_SIZE, Z_DIM, 1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        viz_sample = netG(viz_tensor)\n",
    "        viz_vector = to_np(viz_tensor).reshape(BATCH_SIZE, Z_DIM)\n",
    "        cur_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        np.savetxt(os.path.join(OUT_PATH, 'vec_{}.txt'.format(cur_time)), viz_vector)\n",
    "        vutils.save_image(viz_sample, os.path.join(OUT_PATH, 'img_{}_{}.png'.format(cur_time,i)), nrow=1, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0fstY8FQK_H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
